{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "from caffe import layers as L,params as P,proto,to_proto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# declare file place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定文件的保存路径\n",
    "root='C:/Users/an/Documents/study/caffe_tutorial/caffe_tutorial/'                           #根目录\n",
    "train_list=root+'mnist/train/train.txt'     #训练图片列表\n",
    "test_list=root+'mnist/test/test.txt'        #测试图片列表\n",
    "train_proto=root+'mnist/train.prototxt'     #训练配置文件\n",
    "test_proto=root+'mnist/test.prototxt'       #测试配置文件\n",
    "solver_proto=root+'mnist/solver.prototxt'   #参数文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾caffe2的玩法：\n",
    "\n",
    "- ### 先生成一个modelHelper\n",
    "- ### 使用brew 为 model helper 添加信息\n",
    "- ###  初始化网络参数\n",
    "- ### 使用RunNet 来跑网络\n",
    "- ### model 化为pb文件导出\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## caffe 的玩法\n",
    "- ### 生成配置文件\n",
    "    - ### 第一层：ImageData\n",
    "    - ### 中间成：卷积\n",
    "    - ### 最后：loss\n",
    "    - ### test 中：还有 acc\n",
    "    - 生成过程中的注意事项：\n",
    "        - layers 用于 生成layer\n",
    "        - 数据的流动通过blob，（layer的output）\n",
    "        - 最后用 to_proto 做成prototxt\n",
    "        - 注意到和caffe的区别：caffe 的trainNet中还需要制定优化的网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编写一个函数，生成配置文件prototxt\n",
    "def Lenet(img_list,batch_size,include_acc=False):\n",
    "    #第一层，数据输入层，以ImageData格式输入\n",
    "    data, label = L.ImageData(source=img_list, batch_size=batch_size, ntop=2,root_folder=root,\n",
    "        transform_param=dict(scale= 0.00390625))\n",
    "    #第二层：卷积层\n",
    "    conv1=L.Convolution(data, kernel_size=5, stride=1,num_output=20, pad=0,weight_filler=dict(type='xavier'))\n",
    "    #池化层\n",
    "    pool1=L.Pooling(conv1, pool=P.Pooling.MAX, kernel_size=2, stride=2)\n",
    "    #卷积层\n",
    "    conv2=L.Convolution(pool1, kernel_size=5, stride=1,num_output=50, pad=0,weight_filler=dict(type='xavier'))\n",
    "    #池化层\n",
    "    pool2=L.Pooling(conv2, pool=P.Pooling.MAX, kernel_size=2, stride=2)\n",
    "    #全连接层\n",
    "    fc3=L.InnerProduct(pool2, num_output=500,weight_filler=dict(type='xavier'))\n",
    "    #激活函数层\n",
    "    relu3=L.ReLU(fc3, in_place=True)\n",
    "    #全连接层\n",
    "    fc4 = L.InnerProduct(relu3, num_output=10,weight_filler=dict(type='xavier'))\n",
    "    #softmax层\n",
    "    loss = L.SoftmaxWithLoss(fc4, label)\n",
    "    \n",
    "    if include_acc:             # test阶段需要有accuracy层\n",
    "        acc = L.Accuracy(fc4, label)\n",
    "        return to_proto(loss, acc)\n",
    "    else:\n",
    "        return to_proto(loss)\n",
    "    \n",
    "def write_net():\n",
    "    #写入train.prototxt\n",
    "    with open(train_proto, 'w') as f:\n",
    "        f.write(str(Lenet(train_list,batch_size=64)))\n",
    "\n",
    "    #写入test.prototxt    \n",
    "    with open(test_proto, 'w') as f:\n",
    "        f.write(str(Lenet(test_list,batch_size=100, include_acc=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_solver(solver_file,train_net,test_net):\n",
    "    s=proto.caffe_pb2.SolverParameter()\n",
    "    s.train_net =train_net\n",
    "    s.test_net.append(test_net)\n",
    "    s.test_interval = 938    #60000/64，测试间隔参数：训练完一次所有的图片，进行一次测试  \n",
    "    s.test_iter.append(100)  #10000/100 测试迭代次数，需要迭代100次，才完成一次所有数据的测试\n",
    "    s.max_iter = 9380       #10 epochs , 938*10，最大训练次数\n",
    "    s.base_lr = 0.01    #基础学习率\n",
    "    s.momentum = 0.9    #动量\n",
    "    s.weight_decay = 5e-4  #权值衰减项\n",
    "    s.lr_policy = 'step'   #学习率变化规则\n",
    "    s.stepsize=3000         #学习率变化频率\n",
    "    s.gamma = 0.1          #学习率变化指数\n",
    "    s.display = 20         #屏幕显示间隔\n",
    "#     s.snapshot = 938       #保存caffemodel的间隔\n",
    "    s.snapshot = 2000\n",
    "    s.snapshot_prefix =root+'mnist/lenet'   #caffemodel前缀\n",
    "    s.type ='SGD'         #优化算法\n",
    "    s.solver_mode = proto.caffe_pb2.SolverParameter.GPU    #加速\n",
    "    #写入solver.prototxt\n",
    "    with open(solver_file, 'w') as f:\n",
    "        f.write(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    write_net()\n",
    "    gen_solver(solver_proto,train_proto,test_proto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
